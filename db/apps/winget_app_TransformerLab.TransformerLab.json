{"appId":"winget_app_TransformerLab.TransformerLab","appShortcutName":"Winget Application","appDisplayName":"Transformer Lab","authorId":"winget","releaseTagName":"winget-0.10.0","downloadUrls":{"1":{"installerType":"WindowsInstallerExe","asset":"","url":"https://github.com/transformerlab/transformerlab-app/releases/download/v0.10.0/Transformer-Lab-Setup-0.10.0.exe"},"0":{"installerType":"WindowsInstallerMsi","asset":"","url":""}},"install":{"win32":{"assetId":1,"exec":null,"scope":"User","installerArgs":null},"winarm":null,"linux":null,"linuxArm64":null,"linuxArm7":null,"android":null},"displayImages":[],"description":"100% Open Source Toolkit for Large Language Models: Train, Tune, Chat on your own Machine\n\nTransformer Lab is a free, open-source LLM workspace that you can run on your own computer. It is designed to go beyond what most modern open LLM applications allow. Using Transformer Lab you can easily finetune, evaluate, export and test LLMs across different inference engines and platforms.\nOllama Plugin: If you have ollama installed you can now use that to server GGUF models instead of llama.cpp\nGenerate tab: Generate your own datasets using documents, raw text or from scratch. (You can use to train!)\nDocuments tab: Dedicated page to upload and maintain all documents (for RAG or Generate)\nEvals: Downloadable detailed reports for eval tasks, ability to search for tasks\nTraining: New python completion recipe, several recipe optimizations, added learning rate algorithms to llama_trainer\nBug fixes including:\n- Removed dependencies on unzip, detect if curl is missing\n- Helpful message when you donâ€™t have an available inference engine\n- A number of fixes for issues when using LoRA adapters\n- logprobs no longer freezes when max tokens is reduced","repo":{"author":"microsoft","repo":"winget-pkgs"},"version":"0.10.0","site":"https://transformerlab.ai/","source":"Ali Asaria","license_or_tos":"AGPL-3.0","resources":null,"verified":false}