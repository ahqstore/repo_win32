{"appId":"w:GrafanaLabs.Alloy","appShortcutName":"Alloy","appDisplayName":"Alloy","authorId":"w:winget","releaseTagName":"winget-1.11.0","downloadUrls":{"1":{"installerType":"WindowsInstallerExe","asset":"","url":"https://github.com/grafana/alloy/releases/download/v1.11.0/alloy-installer-windows-amd64.exe"},"0":{"installerType":"WindowsInstallerMsi","asset":"","url":""}},"install":{"win32":{"assetId":1,"exec":null,"scope":"Machine","installerArgs":null},"winarm":null,"linux":null,"linuxArm64":null,"linuxArm7":null,"android":null},"displayImages":[],"description":"Grafana Alloy\n\nOpenTelemetry Collector distribution with programmable pipelines.\nNotable changes:\nBreaking changes\n- Prometheus dependency had a major version upgrade from v2.55.1 to v3.4.2. (@thampiotr)\n  - The . pattern in regular expressions in PromQL matches newline characters now. With this change a regular expressions like .* matches strings that include \\n. This applies to matchers in queries and relabel configs in Prometheus and Loki components.\n  - The enable_http2 in prometheus.remote_write component's endpoints has been changed to false by default. Previously, in Prometheus v2 the remote write http client would default to use http2. In order to parallelize multiple remote write queues across multiple sockets its preferable to not default to http2. If you prefer to use http2 for remote write you must now set enable_http2 to true in your prometheus.remote_write endpoints configuration section.\n  - The experimental CLI flag --feature.prometheus.metric-validation-scheme has been deprecated and has no effect. You can configure the metric validation scheme individually for each prometheus.scrape component.\n  - Log message format has changed for some of the prometheus.* components as part of the upgrade to Prometheus v3.\n  - The values of the le label of classic histograms and the quantile label of summaries are now normalized upon ingestion. In previous Alloy versions, that used Prometheus v2, the value of these labels depended on the scrape protocol (protobuf vs text format) in some situations. This led to label values changing based on the scrape protocol. E.g. a metric exposed as my_classic_hist{le=\"1\"} would be ingested as my_classic_hist{le=\"1\"} via the text format, but as my_classic_hist{le=\"1.0\"} via protobuf. This changed the identity of the metric and caused problems when querying the metric. In current Alloy release, which uses Prometheus v3, these label values will always be normalized to a float like representation. I.e. the above example will always result in my_classic_hist{le=\"1.0\"} being ingested into Prometheus, no matter via which protocol. The effect of this change is that alerts, recording rules and dashboards that directly reference label values as whole numbers such as le=\"1\" will stop working.\n    The recommended way to deal with this change is to fix references to integer le and quantile label values, but otherwise do nothing and accept that some queries that span the transition time will produce inaccurate or unexpected results.\n  See the upstream Prometheus v3 migration guide for more details.\n- prometheus.exporter.windows dependency has been updated to v0.31.1. (@dehaansa)\n  - There are various renamed metrics and two removed collectors (cs, logon).\n- scrape_native_histograms attribute for prometheus.scrape is now set to false, whereas in previous versions of Alloy it would default to true. This means that it is no longer enough to just configure scrape_protocols to start with PrometheusProto to scrape native histograms - scrape_native_histograms has to be enabled. If scrape_native_histograms is enabled, scrape_protocols will automatically be configured correctly for you to include PrometheusProto. If you configure it explicitly, Alloy will validate that PrometheusProto is in the scrape_protocols list.\n- Add otel_attrs_to_hec_metadata configuration block to otelcol.exporter.splunkhec to match otelcol.receiver.splunkhec. (@cgetzen)\n- [otelcol.processor.batch] Two arguments have different default values. (@ptodev)\n  - send_batch_size is now set to 2000 by default. It used to be 8192.\n  - send_batch_max_size is now set to 3000 by default. It used to be 0.\n  - This helps prevent issues with ingestion of batches that are too large.\n- OpenTelemetry Collector dependencies upgraded from v0.128.0 to v0.134.0. (@ptodev)\n  - The otelcol.receiver.opencensus component has been deprecated and will be removed in a future release, use otelcol.receiver.otelp instead.\n  - [otelcol.exporter.*] The deprecated blocking argument in the sending_queue block has been removed.\n    Use block_on_overflow instead.\n  - [otelcol.receiver.kafka, otelcol.exporter.kafka]: Removed the broker_addr argument from the aws_msk block.\n    Also removed the SASL/AWS_MSK_IAM authentication mechanism.\n  - [otelcol.exporter.splunkhec] The batcher block is deprecated and will be removed in a future release. Use the queue block instead.\n  - [otelcol.exporter.loadbalancing] Use a linear probe to decrease variance caused by hash collisions, which was causing a non-uniform distribution of loadbalancing.\n  - [otelcol.connector.servicegraph] The database_name_attribute argument has been removed.\n  - [otelcol.connector.spanmetrics] Adds a default maximum number of exemplars within the metric export interval.\n  - [otelcol.processor.tail_sampling] Add a new block_on_overflow config attribute.\nFeatures\n- Add the otelcol.receiver.fluentforward receiver to receive logs via Fluent Forward Protocol. (@rucciva)\n- Add the prometheus.enrich component to enrich metrics using labels from discovery.* components. (@ArkovKonstantin)\n- Add node_filter configuration block to loki.source.podlogs component to enable node-based filtering for pod discovery. When enabled, only pods running on the specified node will be discovered and monitored, significantly reducing API server load and network traffic in DaemonSet deployments. (@QuentinBisson)\n- (Experimental) Additions to experimental database_observability.mysql component:\n  - query_sample collector now supports auto-enabling the necessary setup_consumers settings (@cristiangreco)\n  - query_sample collector is now compatible with mysql less than 8.0.28 (@cristiangreco)\n  - include server_id label on log entries (@matthewnolf)\n  - support receiving targets argument and relabel those to include server_id (@matthewnolf)\n  - updated the config blocks and documentation (@cristiangreco)\n- (Experimental) Additions to experimental database_observability.postgres component:\n  - add query_tables collector for postgres (@matthewnolf)\n  - add cloud_provider.aws configuration that enables optionally supplying the ARN of the database under observation. The ARN is appended to metric samples as labels for easier filtering and grouping of resources.\n  - add query_sample collector for postgres (@gaantunes)\n  - add schema_table collector for postgres (@fridgepoet)\n  - include server_id label on logs and metrics (@matthewnolf)\n- Add otelcol.receiver.googlecloudpubsub community component to receive metrics, traces, and logs from Google Cloud Pub/Sub subscription. (@eraac)\n- (Experimental) Add a honor_metadata configuration argument to the prometheus.scrape component.\n  When set to true, it will propagate metric metadata to downstream components.\n- Add a flag to pyroscope.ebpf alloy configuration to set the off-cpu profiling threshold. (@luweglarz)\n- Add encoding.url_encode and encoding.url_decode std lib functions. (@kalleep)","repo":{"author":"microsoft","repo":"winget-pkgs"},"version":"1.11.0","site":"https://grafana.com/","source":"Grafana Labs","license_or_tos":"Apache-2.0","resources":null,"verified":false}