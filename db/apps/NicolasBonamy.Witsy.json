{"appId":"w:NicolasBonamy.Witsy","appShortcutName":"Witsy","appDisplayName":"Witsy","authorId":"w:winget","releaseTagName":"winget-3.5.1","downloadUrls":{"0":{"installerType":"WindowsInstallerMsi","asset":"","url":""},"1":{"installerType":"WindowsInstallerExe","asset":"","url":"https://github.com/nbonamy/witsy/releases/download/v3.5.1/Witsy-3.5.1-win32-x64.Setup.exe"}},"install":{"win32":{"assetId":1,"exec":null,"scope":"User","installerArgs":null},"winarm":null,"linux":null,"linuxArm64":null,"linuxArm7":null,"android":null},"displayImages":[],"description":"Desktop AI Assistant / Universal MCP Client\n\nWitsy is a BYOK (Bring Your Own Keys) AI application: it means you need to have API keys for the LLM providers you want to use. Alternatively, you can use Ollama to run models locally on your machine for free and use them in Witsy.\nIt is the first of very few (only?) universal MCP clients:\nWitsy allows you to run MCP servers with virtually any LLM!\nNon-exhaustive feature list:\n- OpenAI, Ollama, Anthropic, MistralAI, Google, xAI, Azure, OpenRouter, DeepSeek, Groq and Cerebras models supported\n- Connect other providers (together, siliconflow, fireworks...) through OpenAI compatibility layer\n- Chat completion with vision models support (describe an image)\n- Text-to-image and text-to video with OpenAI, Google, xAI, Replicate, fal.ai and HuggingFace\n- Image-to-image (image editing) and image-to-video with Google, Replicate and fal.ai\n- LLM plugins to augment LLM: execute python code, search the Internet...\n- Anthropic MCP server support\n- Scratchpad to interactively create the best content with any model!\n- Prompt anywhere allows to generate content directly in any application\n- AI commands runnable on highlighted text in almost any application\n- Experts prompts to specialize your bot on a specific topic\n- Long-term memory plugin to increase relevance of LLM answers\n- Read aloud of assistant messages (requires OpenAI or ElevenLabs API key)\n- Read aloud of any text in other applications (requires OpenAI or ElevenLabs API key)\n- Chat with your local files and documents (RAG)\n- Transcription/Dictation (Speech-to-Text)\n- Realtime Chat aka Voice Mode\n- Anthropic Computer Use support\n- Local history of conversations (with automatic titles)\n- Formatting and copy to clipboard of generated code\n- Conversation PDF export\n- Image copy and download\nAdded\n- Google Base URL\n- Support LM Studio authentication (https://github.com/nbonamy/witsy/issues/525)\n- Show conversations date time creation (https://github.com/nbonamy/witsy/issues/522)\n- \"Scan for Changes\" button for Knowledge Base (https://github.com/nbonamy/witsy/issues/524)\n- Per-server default MCP timeout overrides (https://github.com/nbonamy/witsy/issues/523)\nChanged\n- Performance optimization for message rendering during streaming\n- MCP collision rework (optimistic strategy vs previous pessimistic strategy)\nFixed\n- Bug fixes for markdown tag closing in streamed messages\n- User messages with fenced code blocks render incorrectly in chat history (https://github.com/nbonamy/witsy/issues/526)\n- Design Studio Ollama model not showing (https://github.com/nbonamy/witsy/issues/527)\n- Model change in the right sidebar clears system prompt (https://github.com/nbonamy/witsy/issues/528)\n- Personal Data Saving/Memories Seems Broken (https://github.com/nbonamy/witsy/issues/517)\nRemoved\n- N/A","repo":{"author":"microsoft","repo":"winget-pkgs"},"usrVersion":"3.5.1","version":0,"site":"https://www.bonamy.fr/","source":"Nicolas Bonamy","license_or_tos":"Apache-2.0","resources":null,"verified":false}