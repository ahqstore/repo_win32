{"appId":"w:NicolasBonamy.Witsy","appShortcutName":"Witsy","appDisplayName":"Witsy","authorId":"w:winget","releaseTagName":"winget-3.1.0","downloadUrls":{"0":{"installerType":"WindowsInstallerMsi","asset":"","url":""},"1":{"installerType":"WindowsInstallerExe","asset":"","url":"https://github.com/nbonamy/witsy/releases/download/v3.1.0/Witsy-3.1.0-win32-x64.Setup.exe"}},"install":{"win32":{"assetId":1,"exec":null,"scope":"User","installerArgs":null},"winarm":null,"linux":null,"linuxArm64":null,"linuxArm7":null,"android":null},"displayImages":[],"description":"Desktop AI Assistant / Universal MCP Client\n\nWitsy is a BYOK (Bring Your Own Keys) AI application: it means you need to have API keys for the LLM providers you want to use. Alternatively, you can use Ollama to run models locally on your machine for free and use them in Witsy.\nIt is the first of very few (only?) universal MCP clients:\nWitsy allows you to run MCP servers with virtually any LLM!\nNon-exhaustive feature list:\n- OpenAI, Ollama, Anthropic, MistralAI, Google, xAI, Azure, OpenRouter, DeepSeek, Groq and Cerebras models supported\n- Connect other providers (together, siliconflow, fireworks...) through OpenAI compatibility layer\n- Chat completion with vision models support (describe an image)\n- Text-to-image and text-to video with OpenAI, Google, xAI, Replicate, fal.ai and HuggingFace\n- Image-to-image (image editing) and image-to-video with Google, Replicate and fal.ai\n- LLM plugins to augment LLM: execute python code, search the Internet...\n- Anthropic MCP server support\n- Scratchpad to interactively create the best content with any model!\n- Prompt anywhere allows to generate content directly in any application\n- AI commands runnable on highlighted text in almost any application\n- Experts prompts to specialize your bot on a specific topic\n- Long-term memory plugin to increase relevance of LLM answers\n- Read aloud of assistant messages (requires OpenAI or ElevenLabs API key)\n- Read aloud of any text in other applications (requires OpenAI or ElevenLabs API key)\n- Chat with your local files and documents (RAG)\n- Transcription/Dictation (Speech-to-Text)\n- Realtime Chat aka Voice Mode\n- Anthropic Computer Use support\n- Local history of conversations (with automatic titles)\n- Formatting and copy to clipboard of generated code\n- Conversation PDF export\n- Image copy and download\nAdded\n- Experts categories\n- Sandboxed python runtime\n- Duplicate agent\n- Experts attached to agent step\n- Import Markdown back into conversations (https://github.com/nbonamy/witsy/issues/469)\n- MiniMax Text-to-Speech API (https://github.com/nbonamy/witsy/issues/461)\nChanged\n- Wider engine/model menu (https://github.com/nbonamy/witsy/issues/463)\n- Download button for text mangles python export (https://github.com/nbonamy/witsy/issues/468)\n- Update to Soniox v3 endpoint (https://github.com/nbonamy/witsy/pull/457)\n- Filesystem plugin rewrite\n- More LLM provider error reporting\n- Menu refactor\nFixed\n- Chat color with dark mode (https://github.com/nbonamy/witsy/issues/464)\n- Ollama Chain of Thought / Reasoning in Prompt (https://github.com/nbonamy/witsy/issues/467)\n- Knowledge Base is not shown / canÂ´t be chosen in some languages (https://github.com/nbonamy/witsy/issues/474)\n- Tool calls not showing on main chat when not streaming (https://github.com/nbonamy/witsy/issues/451)\n- Trailing underscore sometimes appearing on messages\nRemoved\n- N/A","repo":{"author":"microsoft","repo":"winget-pkgs"},"usrVersion":"3.1.0","version":0,"site":"https://www.bonamy.fr/","source":"Nicolas Bonamy","license_or_tos":"Apache-2.0","resources":null,"verified":false}