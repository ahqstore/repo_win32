{"appId":"w:Ollama.Ollama","appShortcutName":"Ollama","appDisplayName":"Ollama","authorId":"w:winget","releaseTagName":"winget-0.13.4","downloadUrls":{"0":{"installerType":"WindowsInstallerMsi","asset":"","url":""},"1":{"installerType":"WindowsInstallerExe","asset":"","url":"https://github.com/ollama/ollama/releases/download/v0.13.4/OllamaSetup.exe"}},"install":{"win32":{"assetId":1,"exec":null,"scope":"User","installerArgs":null},"winarm":null,"linux":null,"linuxArm64":null,"linuxArm7":null,"android":null},"displayImages":[],"description":"Get up and running with large language models locally.\n\n\nNew Models\n- Nemotron 3 Nano: A new Standard for Efficient, Open, and Intelligent Agentic Models\n- Olmo 3 and Olmo 3.1: A series of Open language models designed to enable the science of language models. These models are pre-trained on the Dolma 3 dataset and post-trained on the Dolci datasets.\nWhat's Changed\n- Enable Ollama engine by default for remaining models\n- Enable Flash Attention automatically for models by default\n- Fixed handling of long contexts with Gemma 3 models\n- Fixed issue that would occur with Gemma 3 QAT models or other models imported with the Gemma 3 architecture\nNew Contributors\n- @familom made their first contribution in https://github.com/ollama/ollama/pull/13220\nFull Changelog: https://github.com/ollama/ollama/compare/v0.13.3...v0.13.4-rc0","repo":{"author":"microsoft","repo":"winget-pkgs"},"usrVersion":"0.13.4","version":0,"site":"https://ollama.com/","source":"Ollama","license_or_tos":"MIT","resources":null,"verified":false}