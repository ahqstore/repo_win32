{"appId":"w:Ollama.Ollama","appShortcutName":"Winget Application","appDisplayName":"Ollama","authorId":"w:winget","releaseTagName":"winget-0.6.7","downloadUrls":{"1":{"installerType":"WindowsInstallerExe","asset":"","url":"https://github.com/ollama/ollama/releases/download/v0.6.7/OllamaSetup.exe"},"0":{"installerType":"WindowsInstallerMsi","asset":"","url":""}},"install":{"win32":{"assetId":1,"exec":null,"scope":"User","installerArgs":null},"winarm":null,"linux":null,"linuxArm64":null,"linuxArm7":null,"android":null},"displayImages":[],"description":"Get up and running with large language models locally.\n\n\nWhat's Changed\n- Add support for the Llama 4 multimodal models\n- Increased default context window to 4096 tokens\n- Fixed issue where image paths would not be recognized with ~ when being provided to ollama run\n- Improved output quality when using JSON mode in certain scenarios\nNew Contributors\n- @greengrass821 made their first contribution in https://github.com/ollama/ollama/pull/10339\n- @richardshiue made their first contribution in https://github.com/ollama/ollama/pull/10335\n- @aduermael made their first contribution in https://github.com/ollama/ollama/pull/10386\nFull Changelog: https://github.com/ollama/ollama/compare/v0.6.6...v0.6.7-rc0","repo":{"author":"microsoft","repo":"winget-pkgs"},"version":"0.6.7","site":"https://ollama.com/","source":"Ollama","license_or_tos":"MIT","resources":null,"verified":false}