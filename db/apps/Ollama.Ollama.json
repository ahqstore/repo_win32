{"appId":"w:Ollama.Ollama","appShortcutName":"Ollama","appDisplayName":"Ollama","authorId":"w:winget","releaseTagName":"winget-0.12.11","downloadUrls":{"0":{"installerType":"WindowsInstallerMsi","asset":"","url":""},"1":{"installerType":"WindowsInstallerExe","asset":"","url":"https://github.com/ollama/ollama/releases/download/v0.12.11/OllamaSetup.exe"}},"install":{"win32":{"assetId":1,"exec":null,"scope":"User","installerArgs":null},"winarm":null,"linux":null,"linuxArm64":null,"linuxArm7":null,"android":null},"displayImages":[],"description":"Get up and running with large language models locally.\n\n\nWhat's Changed\n- Ollama's API and the OpenAI-compatible API now supports Logprobs\n- Ollama's new app now supports WebP images\n- Improved rendering performance in Ollama's new app, especially when rendering code\n- The \"required\" field in tool definitions will now be omitted if not specified\n- Fixed issue where \"tool_call_id\" would be omitted when using the OpenAI-compatible API.\n- Fixed issue where ollama create would import data from both consolidated.safetensors and other safetensor files.\n- Ollama will now prefer dedicated GPUs over iGPUs when scheduling models\n- Vulkan can now be enabled by setting OLLAMA_VULKAN=1. For example: OLLAMA_VULKAN=1 ollama serve\nNew Contributors\n- @mags0ft made their first contribution in https://github.com/ollama/ollama/pull/11371\n- @macarronesc made their first contribution in https://github.com/ollama/ollama/pull/12973\n- @breatn made their first contribution in https://github.com/ollama/ollama/pull/12985\n- @cybardev made their first contribution in https://github.com/ollama/ollama/pull/13045\n- @baptistejamin made their first contribution in https://github.com/ollama/ollama/pull/12899\nFull Changelog: https://github.com/ollama/ollama/compare/v0.12.10...v0.12.11-rc1","repo":{"author":"microsoft","repo":"winget-pkgs"},"usrVersion":"0.12.11","version":0,"site":"https://ollama.com/","source":"Ollama","license_or_tos":"MIT","resources":null,"verified":false}