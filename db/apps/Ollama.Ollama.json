{"appId":"w:Ollama.Ollama","appShortcutName":"Ollama","appDisplayName":"Ollama","authorId":"w:winget","releaseTagName":"winget-0.13.0","downloadUrls":{"0":{"installerType":"WindowsInstallerMsi","asset":"","url":""},"1":{"installerType":"WindowsInstallerExe","asset":"","url":"https://github.com/ollama/ollama/releases/download/v0.13.0/OllamaSetup.exe"}},"install":{"win32":{"assetId":1,"exec":null,"scope":"User","installerArgs":null},"winarm":null,"linux":null,"linuxArm64":null,"linuxArm7":null,"android":null},"displayImages":[],"description":"Get up and running with large language models locally.\n\n\nNew models\n- DeepSeek-OCR: DeepSeek-OCR uses optical 2D mapping to compress long contexts, achieving high OCR precision with reduced vision tokens and demonstrating practical value in document processing.\n- Cogito-V2.1: instruction tuned generative models, currently the best open-weight LLM by a US company\nDeepSeek-OCR\nDeepSeek-OCR is now available on Ollama. Example inputs:\nollama run deepseek-ocr \"/path/to/image\\n<|grounding|>Given the layout of the image.\"\nollama run deepseek-ocr \"/path/to/image\\nFree OCR.\"\nollama run deepseek-ocr \"/path/to/image\\nParse the figure.\"\nollama run deepseek-ocr \"/path/to/image\\nExtract the text in the image.\"\nollama run deepseek-ocr \"/path/to/image\\n<|grounding|>Convert the document to markdown.\"\nNew bench tool\nOllama's GitHub repo now includes a bench tool that can be used to test model performance. For the time being this is a separate tool that can be built in the Ollama GitHub repository:\nFirst, install Go. Then from the root of the Ollama repository run:\ngo run ./cmd/bench.go -model gpt-oss:20b\nFor more information see the tool's documentation\nWhat's Changed\n- DeepSeek-OCR is now supported\n- DeepSeek-V3.1 architecture is now supported in Ollama's engine\n- Fixed performance issues that arose in Ollama 0.12.11 on CUDA\n- Fixed issue where Linux install packages were missing required Vulkan libraries\n- Improved CPU and memory detection while in containers/cgroups\n- Improved VRAM information detection for AMD GPUs\n- Improved KV cache performance to no longer require defragmentation\nNew Contributors\n- @lnicola made their first contribution in https://github.com/ollama/ollama/pull/13096\n- @vignesh1507 made their first contribution in https://github.com/ollama/ollama/pull/13078\n- @pierwill made their first contribution in https://github.com/ollama/ollama/pull/12995\n- @jjuliano made their first contribution in https://github.com/ollama/ollama/pull/11877\n- @omahs made their first contribution in https://github.com/ollama/ollama/pull/10683\n- @SiLeader made their first contribution in https://github.com/ollama/ollama/pull/10292\n- @ssam18 made their first contribution in https://github.com/ollama/ollama/pull/13124\n- @seolyam made their first contribution in https://github.com/ollama/ollama/pull/13116\nFull Changelog: https://github.com/ollama/ollama/compare/v0.12.11...v0.13.0-rc0","repo":{"author":"microsoft","repo":"winget-pkgs"},"usrVersion":"0.13.0","version":0,"site":"https://ollama.com/","source":"Ollama","license_or_tos":"MIT","resources":null,"verified":false}