{"appId":"w:Ollama.Ollama","appShortcutName":"Winget Application","appDisplayName":"Ollama","authorId":"w:winget","releaseTagName":"winget-0.6.3","downloadUrls":{"0":{"installerType":"WindowsInstallerMsi","asset":"","url":""},"1":{"installerType":"WindowsInstallerExe","asset":"","url":"https://github.com/ollama/ollama/releases/download/v0.6.3/OllamaSetup.exe"}},"install":{"win32":{"assetId":1,"exec":null,"scope":"User","installerArgs":null},"winarm":null,"linux":null,"linuxArm64":null,"linuxArm7":null,"android":null},"displayImages":[],"description":"Get up and running with large language models locally.\n\n\nWhat's Changed\n- New sliding window attention optimizations for Gemma 3, improving inference speed and memory allocation for long context windows.\n- Improved loading speed of Gemma 3\n- ollama create will now return the name of unsupported architectures\n- Fixed error talloc->buffer_id >= 0 when running a model\n- Fixed (int)sched->hash_set.size >= graph->n_nodes + graph->n_leafs error when running a model\n- ollama create will now automatically select the right template when importing Gemma 3 from safetensors\n- ollama show -v will now correctly render boolean values as true or false\nNew Contributors\n- @rylativity made their first contribution in https://github.com/ollama/ollama/pull/9874\nFull Changelog: https://github.com/ollama/ollama/compare/v0.6.2...v0.6.3","repo":{"author":"microsoft","repo":"winget-pkgs"},"version":"0.6.3","site":"https://ollama.com/","source":"Ollama","license_or_tos":"MIT","resources":null,"verified":false}